#!/usr/bin/env python3
# =============================================================
# ğŸ§ Aila Whisper ä¸»ç›‘å¬ç¨‹åº
# -------------------------------------------------------------
# åŠŸèƒ½ï¼š
# 1. å®æ—¶å½•éŸ³å¹¶è¯†åˆ«è¯­éŸ³
# 2. æ£€æµ‹å”¤é†’è¯ "Aila" / "è‰¾æ‹‰"
# 3. è°ƒç”¨ Ollama è·å–è‡ªç„¶è¯­è¨€å›å¤
# 4. è°ƒç”¨ Piper åˆæˆè¯­éŸ³è¾“å‡º
# =============================================================

import os, subprocess, json, sounddevice as sd, soundfile as sf, numpy as np, time, yaml

# === è¯»å–é…ç½®æ–‡ä»¶ ===
config_path = os.getenv("WHISPER_CONFIG", "/etc/whisper/config.yaml")
with open(config_path, "r") as f:
    config = yaml.safe_load(f)

MODEL_PATH = config.get("model_path", "/aila/models/whisper-small.bin")
VOICE_MODEL = config.get("voice_model", "/aila/models/piper-zh-xiaoyue.onnx")
SAMPLE_RATE = config.get("sample_rate", 16000)
LANG = config.get("language", "zh")
OLLAMA_URL = "http://localhost:11434/api/generate"
WAKE_WORDS = ["aila", "è‰¾æ‹‰"]

# === è¾…åŠ©å‡½æ•° ===
def transcribe(audio):
    """è°ƒç”¨ whisper.cpp è½¬å½•éŸ³é¢‘æ®µ"""
    tmpfile = "/tmp/chunk.wav"
    sf.write(tmpfile, audio, SAMPLE_RATE)
    result = subprocess.run(
        ["whispercpp", "--model", MODEL_PATH, "--language", LANG, "--file", tmpfile],
        capture_output=True, text=True
    )
    return result.stdout.strip()

def speak(text):
    """è°ƒç”¨ Piper è¯­éŸ³è¾“å‡º"""
    tmpfile = "/tmp/tts.wav"
    print(f"ğŸ—£ï¸ Aila è¯´: {text}")
    subprocess.run(
        ["piper", "--model", VOICE_MODEL, "--output_file", tmpfile],
        input=text.encode("utf-8"), stdout=subprocess.DEVNULL
    )
    subprocess.run(["aplay", tmpfile], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def generate_reply(prompt):
    """å‘é€ prompt ç»™ Ollama"""
    payload = {"model": "llama3.2", "prompt": f"ä½ æ˜¯ä¸€ä¸ªåå«Ailaçš„å°å¥³å­©ï¼Œç”¨æ¸©æŸ”è‡ªç„¶çš„è¯­æ°”å›ç­”ï¼š{prompt}"}
    resp = subprocess.run(
        ["curl", "-s", "-X", "POST", OLLAMA_URL, "-d", json.dumps(payload)],
        capture_output=True, text=True
    )
    return resp.stdout.strip()

# === ä¸»å¾ªç¯ ===
def main():
    print("ğŸ§ æ­£åœ¨ç›‘å¬éº¦å…‹é£... è¯´å‡º 'Aila' æˆ– 'è‰¾æ‹‰' å”¤é†’å¥¹ã€‚")
    while True:
        audio = sd.rec(int(SAMPLE_RATE * 4), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        text = transcribe(audio)
        if not text:
            continue
        print(f"ğŸ—£ï¸ å¬åˆ°: {text}")
        if any(w in text.lower() for w in WAKE_WORDS):
            print("âœ¨ æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¯åŠ¨ Ollama...")
            reply = generate_reply("ä½ å¥½ã€‚")
            if reply:
                speak(reply)
        time.sleep(1)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("ğŸ›‘ æ‰‹åŠ¨ç»“æŸã€‚")
