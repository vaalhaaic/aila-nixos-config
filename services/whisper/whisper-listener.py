#!/usr/bin/env python3
import os, time, subprocess, json, sounddevice as sd, numpy as np

WAKE_WORD = "aila"
SAMPLE_RATE = 16000
BLOCK_DURATION = 3  # ç§’

MODEL_PATH = "/aila/models/whisper-small.bin"
OLLAMA_URL = "http://localhost:11434/api/generate"
TTS_SCRIPT = "/usr/local/bin/tts-speak.sh"  # å¾…å†™

def transcribe_chunk(audio):
    """è°ƒç”¨ whisper.cpp è½¬å½•éŸ³é¢‘æ®µ"""
    tmpfile = "/tmp/chunk.wav"
    import soundfile as sf
    sf.write(tmpfile, audio, SAMPLE_RATE)
    result = subprocess.run(
        ["whispercpp", "--model", MODEL_PATH, "--file", tmpfile, "--language", "zh"],
        capture_output=True, text=True
    )
    return result.stdout.strip()

def send_to_ollama(prompt):
    """å‘é€åˆ° Ollama å¹¶è¿”å›å›å¤"""
    payload = {"model": "llama3.2", "prompt": f"ä½ æ˜¯ä¸€ä¸ªåå«Ailaçš„å°å¥³å­©ï¼Œè¯·è‡ªç„¶åœ°å›ç­”ï¼š{prompt}"}
    resp = subprocess.run(
        ["curl", "-s", "-X", "POST", OLLAMA_URL, "-d", json.dumps(payload)],
        capture_output=True, text=True
    )
    return resp.stdout

def main():
    print("ğŸ§ æ­£åœ¨ç›‘å¬éº¦å…‹é£ï¼ˆè¯´å‡ºâ€œè‰¾æ‹‰â€å”¤é†’ï¼‰...")
    while True:
        audio = sd.rec(int(SAMPLE_RATE * BLOCK_DURATION), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        text = transcribe_chunk(audio)
        if not text:
            continue
        print("ğŸ—£ï¸ å¬åˆ°:", text)
        if WAKE_WORD in text.lower() or "è‰¾æ‹‰" in text:
            print("âœ¨ æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¯åŠ¨ Ollama ç”Ÿæˆ...")
            reply = send_to_ollama("ä½ å¥½ï¼ŒAilaã€‚")
            print("ğŸ’¬ å›å¤:", reply)
            subprocess.run([TTS_SCRIPT, reply])
        time.sleep(0.5)

if __name__ == "__main__":
    main()
